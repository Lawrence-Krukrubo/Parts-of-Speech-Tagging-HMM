{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter \"magic methods\" -- only need to be run once per kernel restart\n",
    "%load_ext autoreload\n",
    "%aimport helpers\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules -- this cell needs to be run again if you make changes to any of the files\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from helpers import show_model\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_sentences = ['Mary Jane can see Will', \\\n",
    "                     'Spot will see Mary', \\\n",
    "                     'Will Jane spot Mary?', \\\n",
    "                     'Mary will pat Spot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's clean the original sentences, remove punctuations, convert each word to Caps and remove duplicate words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "words = set()\n",
    "for sentence in original_sentences:\n",
    "    split = sentence.split()\n",
    "    for word in split:\n",
    "        x = word.translate(str.maketrans('', '',string.punctuation))\n",
    "        x = x.capitalize()\n",
    "        words.add(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jane', 'Will', 'Can', 'Pat', 'Spot', 'Mary', 'See']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(words)\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's create the emmission_probs and change the order of words to conform to the video style:**<br>\n",
    "Emission probability is the probability that a certain word is of a specific part of speech. E.G, Mary is a Noun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>modal</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Will</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spot</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>See</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pat</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      noun  modal  verb\n",
       "Mary     4      0     0\n",
       "Jane     2      0     0\n",
       "Will     1      3     0\n",
       "Spot     2      0     1\n",
       "Can      0      1     0\n",
       "See      0      0     2\n",
       "Pat      0      0     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_probs = {'noun':[4, 2, 1, 2, 0, 0, 0], \\\n",
    "                 'modal':[0, 0, 3, 0, 1, 0, 0], \\\n",
    "                 'verb':[0, 0, 0, 1, 0, 2, 1]}\n",
    "\n",
    "words = ['Mary', 'Jane', 'Will', 'Spot', 'Can', 'See', 'Pat']\n",
    "emissions_df = pd.DataFrame(emission_probs)\n",
    "emissions_df.index = words\n",
    "\n",
    "emissions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to find the emission probabilities, let's divide each column by its sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in emissions_df.columns:\n",
    "    emissions_df[i] /= np.sum(emissions_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>modal</th>\n",
       "      <th>verb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mary</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jane</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Will</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spot</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Can</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>See</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          noun  modal  verb\n",
       "Mary  0.444444   0.00  0.00\n",
       "Jane  0.222222   0.00  0.00\n",
       "Will  0.111111   0.75  0.00\n",
       "Spot  0.222222   0.00  0.25\n",
       "Can   0.000000   0.25  0.00\n",
       "See   0.000000   0.00  0.50\n",
       "Pat   0.000000   0.00  0.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emissions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's also create the transition_probs and change the order of words to conform to the video style:**\n",
    "\n",
    "Transition probability is the probability that a part of speech ike a Noun, follows another part, like a Verb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>modal</th>\n",
       "      <th>verb</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noun</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modal</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           noun     modal      verb       tag\n",
       "tag    0.750000  0.250000  0.000000  0.000000\n",
       "noun   0.111111  0.333333  0.111111  0.444444\n",
       "modal  0.250000  0.000000  0.750000  0.000000\n",
       "verb   1.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transition_probs = {'noun':[3/4, 1/9, 1/4, 1], \\\n",
    "                 'modal':[1/4, 1/3, 0, 0], \\\n",
    "                 'verb':[0, 1/9, 3/4, 0], \\\n",
    "                   'tag':[0, 4/9, 0, 0]}\n",
    "\n",
    "transitions_df = pd.DataFrame(transition_probs)\n",
    "transitions_df.index = [transitions_df.columns[-1]] + list(transitions_df.columns[:-1])\n",
    "\n",
    "transitions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hidden Markov Models:</h2>\n",
    "\n",
    "Let's start assembling our HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the HMM model\n",
    "model = HiddenMarkovModel(name=\"Speech\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission probability distributions, P(Word | Noun)\n",
    "noun_dict = {i:round(j, 4) for i,j in zip(emissions_df.index, emissions_df.noun)}\n",
    "\n",
    "noun_emissions = DiscreteDistribution(noun_dict)\n",
    "noun_state = State(noun_emissions, name=\"Noun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission probability distributions, P(Word | Modal)\n",
    "modal_dict = {i:round(j, 4) for i,j in zip(emissions_df.index, emissions_df.modal)}\n",
    "\n",
    "modal_emissions = DiscreteDistribution(modal_dict)\n",
    "modal_state = State(modal_emissions, name=\"Modal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission probability distributions, P(Word | Verb)\n",
    "verb_dict = {i:round(j, 4) for i,j in zip(emissions_df.index, emissions_df.verb)}\n",
    "\n",
    "verb_emissions = DiscreteDistribution(verb_dict)\n",
    "verb_state = State(verb_emissions, name=\"Verb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets add the states to the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the states to the model\n",
    "model.add_states(noun_state, modal_state, verb_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMPLEMENTATION:** Adding Transitions\n",
    "Once the states are added to the model, we can build up the desired topology of individual state transitions.\n",
    "\n",
    "#### Initial Probability $P(X_0)$:\n",
    "We will assume that we don't know anything useful about the likelihood of a sequence starting in either state. If the sequences start on a Verb and end on a Noun (so each pattern is a new sequence). We can assign equal probability to each starting state by setting $P(X_0=Noun) = 0.3333$ and $P(X_0=Modal)=0.3333$ and $P(X_0=Verb)=0.3333$:\n",
    "\n",
    "| $Noun$ | $Modal$ | $Verb$ |\n",
    "| --- | --- | --- |\n",
    "| 0.3333 | 0.3333 | 0.3333 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>modal</th>\n",
       "      <th>verb</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noun</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modal</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           noun     modal      verb       tag\n",
       "tag    0.750000  0.250000  0.000000  0.000000\n",
       "noun   0.111111  0.333333  0.111111  0.444444\n",
       "modal  0.250000  0.000000  0.750000  0.000000\n",
       "verb   1.000000  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_transition(model.start, noun_state, 0.750000)\n",
    "model.add_transition(model.start, modal_state, 0.250000)\n",
    "model.add_transition(model.start, verb_state, 0.000000)\n",
    "model.add_transition(model.start, model.end, 0.000000)\n",
    "model.add_transition(noun_state, noun_state, 0.111111)\n",
    "model.add_transition(noun_state, modal_state, 0.333333)\n",
    "model.add_transition(noun_state, verb_state, 0.111111)\n",
    "model.add_transition(noun_state, model.end, 0.444444)\n",
    "model.add_transition(modal_state, noun_state, 0.250000)\n",
    "model.add_transition(modal_state, modal_state, 0.000000)\n",
    "model.add_transition(modal_state, verb_state, 0.750000)\n",
    "model.add_transition(modal_state, model.end, 0.000000)\n",
    "model.add_transition(verb_state, noun_state, 1.000000)\n",
    "model.add_transition(verb_state, modal_state, 0.000000)\n",
    "model.add_transition(verb_state, verb_state, 0.000000)\n",
    "model.add_transition(verb_state, model.end, 0.000000)\n",
    "model.bake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.edge_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.node_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] \"dot\" not found in path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\sisok\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1911\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1912\u001b[1;33m             stdout_data, stderr_data, process = call_graphviz(\n\u001b[0m\u001b[0;32m   1913\u001b[0m                 \u001b[0mprogram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sisok\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcall_graphviz\u001b[1;34m(program, arguments, working_dir, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m     process = subprocess.Popen(\n\u001b[0m\u001b[0;32m    130\u001b[0m         \u001b[0mprogram_with_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sisok\\appdata\\local\\programs\\python\\python38\\lib\\subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[0;32m    853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 854\u001b[1;33m             self._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0m\u001b[0;32m    855\u001b[0m                                 \u001b[0mpass_fds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sisok\\appdata\\local\\programs\\python\\python38\\lib\\subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1306\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1307\u001b[1;33m                 hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[0m\u001b[0;32m   1308\u001b[0m                                          \u001b[1;31m# no special security\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-3d2f87761aa7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mshow_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Speech.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_ends\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\PycharmProjects\\Parts-of-Speech-tagging-HMM\\HMM\\helpers.py\u001b[0m in \u001b[0;36mshow_model\u001b[1;34m(model, figsize, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \"\"\"\n\u001b[0;32m     94\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel2png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\PycharmProjects\\Parts-of-Speech-tagging-HMM\\HMM\\helpers.py\u001b[0m in \u001b[0;36mmodel2png\u001b[1;34m(model, filename, overwrite, show_ends)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mpydot_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrawing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnx_pydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mpydot_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_rankdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"LR\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mpng_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[0mimg_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[0mimg_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpng_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sisok\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(f, prog, encoding)\u001b[0m\n\u001b[0;32m   1720\u001b[0m                     encoding=None):\n\u001b[0;32m   1721\u001b[0m                 \u001b[1;34m\"\"\"Refer to docstring of method `create`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1722\u001b[1;33m                 return self.create(\n\u001b[0m\u001b[0;32m   1723\u001b[0m                     format=f, prog=prog, encoding=encoding)\n\u001b[0;32m   1724\u001b[0m             \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'create_{fmt}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\sisok\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1920\u001b[0m                 args[1] = '\"{prog}\" not found in path.'.format(\n\u001b[0;32m   1921\u001b[0m                     prog=prog)\n\u001b[1;32m-> 1922\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1923\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1924\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] \"dot\" not found in path."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_model(model, figsize=(8, 8), filename=\"Speech.png\", overwrite=True, show_ends=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Model\n",
    "The states of the model can be accessed using array syntax on the `HMM.states` attribute, and the transition matrix can be accessed by calling `HMM.dense_transition_matrix()`. Element $(i, j)$ encodes the probability of transitioning from state $i$ to state $j$.\n",
    "\n",
    "Run the next cell to inspect the full state transition matrix, then read the . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's reorder the pomegranate default column orderings putting start first and last, last**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = [\"Speech-start\", \"Modal\", \"Noun\", \"Verb\", \"Speech-end\"]  # Override the Pomegranate default order\n",
    "column_names = [s.name for s in model.states]\n",
    "order_index = [column_names.index(c) for c in column_order]\n",
    "print(order_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-order the rows/columns to match the specified column order\n",
    "transitions = model.dense_transition_matrix()[:, order_index][order_index, :]\n",
    "print(\"The state transition matrix, P(Xt|Xt-1):\\n\")\n",
    "print(transitions)\n",
    "print(\"\\nThe transition probability from Noun to Modal is {:.0f}%\".format(100 * transitions[2, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions[2, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The transition matrix here is arranged in the following fashion:**\n",
    "\n",
    "1. The columns go down [Start, Modal, Noun, Verb, End]\n",
    "2. The rows go across [Start, Modal, Noun, Verb, End] too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Inference in Hidden Markov Models</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPLEMENTATION: Calculate Sequence Likelihood\n",
    "\n",
    "Calculating the likelihood of an observation sequence from an HMM network is performed with the [forward algorithm](https://en.wikipedia.org/wiki/Forward_algorithm). Pomegranate provides the the `HMM.forward()` method to calculate the full matrix showing the likelihood of aligning each observation to each state in the HMM, and the `HMM.log_probability()` method to calculate the cumulative likelihood over all possible hidden state paths that the specified model generated the observation sequence.\n",
    "\n",
    "Fill in the code in the next section with a sample observation sequence and then use the `forward()` and `log_probability()` methods to evaluate the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = ['Jane', 'Will', 'Spot', 'Will']\n",
    "assert len(observations) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use model.forward() to calculate the forward matrix of the observed sequence,\n",
    "# and then use np.exp() to convert from log-likelihood to likelihood\n",
    "forward_matrix = np.exp(model.forward(observations))\n",
    "forward_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use model.log_probability() to calculate the all-paths likelihood of the\n",
    "# observed sequence and then use np.exp() to convert log-likelihood to likelihood\n",
    "probability_percentage = np.exp(model.log_probability(observations))\n",
    "probability_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the forward probabilities\n",
    "print(\"         \" + \"\".join(s.name.center(len(s.name)+6) for s in model.states))\n",
    "for i in range(len(observations) + 1):\n",
    "    print(\" <start> \" if i==0 else observations[i - 1].center(9), end=\"\")\n",
    "    print(\"\".join(\"{:.0f}%\".format(100 * forward_matrix[i, j]).center(len(s.name) + 6)\n",
    "                  for j, s in enumerate(model.states)))\n",
    "\n",
    "print(\"\\nThe likelihood over all possible paths \" + \\\n",
    "      \"of this model producing the sequence {} is {:.2f}%\\n\\n\"\n",
    "      .format(observations, 100 * probability_percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Decoding the Most Likely Hidden State Sequence\n",
    "\n",
    "The [Viterbi algorithm](https://en.wikipedia.org/wiki/Viterbi_algorithm) calculates the single path with the highest likelihood to produce a specific observation sequence. Pomegranate provides the `HMM.viterbi()` method to calculate both the hidden state sequence and the corresponding likelihood of the viterbi path.\n",
    "\n",
    "This is called \"decoding\" because we use the observation sequence to decode the corresponding hidden state sequence. In the part of speech tagging problem, the hidden states map to parts of speech and the observations map to sentences. Given a sentence, Viterbi decoding finds the most likely sequence of part of speech tags corresponding to the sentence.\n",
    "\n",
    "Fill in the code in the next section with the same sample observation sequence you used above, and then use the `model.viterbi()` method to calculate the likelihood and most likely state sequence. Compare the Viterbi likelihood against the forward algorithm likelihood for the observation sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use model.viterbi to find the sequence likelihood & the most likely path\n",
    "viterbi_likelihood, viterbi_path = model.viterbi(observations)\n",
    "\n",
    "print(\"The most likely Speech sequence to have generated \" + \\\n",
    "      \"these observations is {} at {:.2f}%.\"\n",
    "      .format([s[1].name for s in viterbi_path[1:]], np.exp(viterbi_likelihood)*100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the most likely paths to generate all 4 original sentences using viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = ['Mary', 'Jane', 'Can', \"See\", 'Will']\n",
    "viterbi_likelihood, viterbi_path = model.viterbi(observations)\n",
    "\n",
    "print(\"The most likely Speech sequence to have generated \" + \\\n",
    "      \"these observations is {} at {:.2f}%.\"\n",
    "      .format([s[1].name for s in viterbi_path[1:]], np.exp(viterbi_likelihood)*100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = ['Spot', 'Will', \"See\", 'Mary']\n",
    "viterbi_likelihood, viterbi_path = model.viterbi(observations)\n",
    "\n",
    "print(\"The most likely Speech sequence to have generated \" + \\\n",
    "      \"these observations is {} at {:.2f}%.\"\n",
    "      .format([s[1].name for s in viterbi_path[1:]], np.exp(viterbi_likelihood)*100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = ['Will', \"Jane\", 'Spot', 'Mary']\n",
    "viterbi_likelihood, viterbi_path = model.viterbi(observations)\n",
    "\n",
    "print(\"The most likely Speech sequence to have generated \" + \\\n",
    "      \"these observations is {} at {:.2f}%.\"\n",
    "      .format([s[1].name for s in viterbi_path[1:]], np.exp(viterbi_likelihood)*100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = ['Mary', 'Will', \"Pat\", 'Spot']\n",
    "viterbi_likelihood, viterbi_path = model.viterbi(observations)\n",
    "\n",
    "print(\"The most likely Speech sequence to have generated \" + \\\n",
    "      \"these observations is {} at {:.2f}%.\"\n",
    "      .format([s[1].name for s in viterbi_path[1:]], np.exp(viterbi_likelihood)*100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
